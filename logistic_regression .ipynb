{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a559becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62796caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:/Users/mail2/OneDrive/Desktop/ML-2022/Ml_Data/cansor_breast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "538f7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop([\"Unnamed: 32\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0458ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data.iloc[:,2:]\n",
    "Y_target=data.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f0d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e1d74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(X_feature,Y_target,test_size=.30,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42901bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail2\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "trainer=LogisticRegression()\n",
    "learner=trainer.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccfed2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07934758",
   "metadata": {},
   "outputs": [],
   "source": [
    "YP=learner.predict(Xtest)\n",
    "YA=Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c804625",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=accuracy_score(YP,YA)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6daf5c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.39766081871345"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e210a2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.36</td>\n",
       "      <td>18.54</td>\n",
       "      <td>79.01</td>\n",
       "      <td>466.7</td>\n",
       "      <td>0.08477</td>\n",
       "      <td>0.06815</td>\n",
       "      <td>0.02643</td>\n",
       "      <td>0.01921</td>\n",
       "      <td>0.1602</td>\n",
       "      <td>0.06066</td>\n",
       "      <td>...</td>\n",
       "      <td>13.29</td>\n",
       "      <td>27.49</td>\n",
       "      <td>85.56</td>\n",
       "      <td>544.1</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.19630</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.08442</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.07185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>14.04</td>\n",
       "      <td>15.98</td>\n",
       "      <td>89.78</td>\n",
       "      <td>611.2</td>\n",
       "      <td>0.08458</td>\n",
       "      <td>0.05895</td>\n",
       "      <td>0.03534</td>\n",
       "      <td>0.02944</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.05898</td>\n",
       "      <td>...</td>\n",
       "      <td>15.66</td>\n",
       "      <td>21.58</td>\n",
       "      <td>101.20</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.11950</td>\n",
       "      <td>0.12520</td>\n",
       "      <td>0.11170</td>\n",
       "      <td>0.07453</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.07234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>12.91</td>\n",
       "      <td>16.33</td>\n",
       "      <td>82.53</td>\n",
       "      <td>516.4</td>\n",
       "      <td>0.07941</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.03873</td>\n",
       "      <td>0.02377</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>13.88</td>\n",
       "      <td>22.00</td>\n",
       "      <td>90.81</td>\n",
       "      <td>600.6</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.15060</td>\n",
       "      <td>0.17640</td>\n",
       "      <td>0.08235</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.06949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>16.11</td>\n",
       "      <td>18.05</td>\n",
       "      <td>105.10</td>\n",
       "      <td>813.0</td>\n",
       "      <td>0.09721</td>\n",
       "      <td>0.11370</td>\n",
       "      <td>0.09447</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.06248</td>\n",
       "      <td>...</td>\n",
       "      <td>19.92</td>\n",
       "      <td>25.27</td>\n",
       "      <td>129.00</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>0.13140</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.28020</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.2792</td>\n",
       "      <td>0.08158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>12.43</td>\n",
       "      <td>17.00</td>\n",
       "      <td>78.60</td>\n",
       "      <td>477.3</td>\n",
       "      <td>0.07557</td>\n",
       "      <td>0.03454</td>\n",
       "      <td>0.01342</td>\n",
       "      <td>0.01699</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.05561</td>\n",
       "      <td>...</td>\n",
       "      <td>12.90</td>\n",
       "      <td>20.21</td>\n",
       "      <td>81.76</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.08409</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>0.02237</td>\n",
       "      <td>0.02832</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.05932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>11.57</td>\n",
       "      <td>19.04</td>\n",
       "      <td>74.20</td>\n",
       "      <td>409.7</td>\n",
       "      <td>0.08546</td>\n",
       "      <td>0.07722</td>\n",
       "      <td>0.05485</td>\n",
       "      <td>0.01428</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>0.06267</td>\n",
       "      <td>...</td>\n",
       "      <td>13.07</td>\n",
       "      <td>26.98</td>\n",
       "      <td>86.43</td>\n",
       "      <td>520.5</td>\n",
       "      <td>0.12490</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.25600</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.08284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>13.85</td>\n",
       "      <td>15.18</td>\n",
       "      <td>88.99</td>\n",
       "      <td>587.4</td>\n",
       "      <td>0.09516</td>\n",
       "      <td>0.07688</td>\n",
       "      <td>0.04479</td>\n",
       "      <td>0.03711</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.05853</td>\n",
       "      <td>...</td>\n",
       "      <td>14.98</td>\n",
       "      <td>21.74</td>\n",
       "      <td>98.37</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.11850</td>\n",
       "      <td>0.17240</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.09993</td>\n",
       "      <td>0.2955</td>\n",
       "      <td>0.06912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10.26</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.06569</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>15.37</td>\n",
       "      <td>22.76</td>\n",
       "      <td>100.20</td>\n",
       "      <td>728.2</td>\n",
       "      <td>0.09200</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.11220</td>\n",
       "      <td>0.07483</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.06097</td>\n",
       "      <td>...</td>\n",
       "      <td>16.43</td>\n",
       "      <td>25.84</td>\n",
       "      <td>107.50</td>\n",
       "      <td>830.9</td>\n",
       "      <td>0.12570</td>\n",
       "      <td>0.19970</td>\n",
       "      <td>0.28460</td>\n",
       "      <td>0.14760</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.06828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>11.76</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.02685</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>...</td>\n",
       "      <td>13.36</td>\n",
       "      <td>23.39</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.11370</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "107        12.36         18.54           79.01      466.7          0.08477   \n",
       "437        14.04         15.98           89.78      611.2          0.08458   \n",
       "195        12.91         16.33           82.53      516.4          0.07941   \n",
       "141        16.11         18.05          105.10      813.0          0.09721   \n",
       "319        12.43         17.00           78.60      477.3          0.07557   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "420        11.57         19.04           74.20      409.7          0.08546   \n",
       "279        13.85         15.18           88.99      587.4          0.09516   \n",
       "390        10.26         12.22           65.75      321.6          0.09996   \n",
       "91         15.37         22.76          100.20      728.2          0.09200   \n",
       "297        11.76         18.14           75.00      431.1          0.09968   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "107           0.06815         0.02643              0.01921         0.1602   \n",
       "437           0.05895         0.03534              0.02944         0.1714   \n",
       "195           0.05366         0.03873              0.02377         0.1829   \n",
       "141           0.11370         0.09447              0.05943         0.1861   \n",
       "319           0.03454         0.01342              0.01699         0.1472   \n",
       "..                ...             ...                  ...            ...   \n",
       "420           0.07722         0.05485              0.01428         0.2031   \n",
       "279           0.07688         0.04479              0.03711         0.2110   \n",
       "390           0.07542         0.01923              0.01968         0.1800   \n",
       "91            0.10360         0.11220              0.07483         0.1717   \n",
       "297           0.05914         0.02685              0.03515         0.1619   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "107                 0.06066  ...         13.29          27.49   \n",
       "437                 0.05898  ...         15.66          21.58   \n",
       "195                 0.05667  ...         13.88          22.00   \n",
       "141                 0.06248  ...         19.92          25.27   \n",
       "319                 0.05561  ...         12.90          20.21   \n",
       "..                      ...  ...           ...            ...   \n",
       "420                 0.06267  ...         13.07          26.98   \n",
       "279                 0.05853  ...         14.98          21.74   \n",
       "390                 0.06569  ...         11.38          15.65   \n",
       "91                  0.06097  ...         16.43          25.84   \n",
       "297                 0.06287  ...         13.36          23.39   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "107            85.56       544.1           0.11840            0.19630   \n",
       "437           101.20       750.0           0.11950            0.12520   \n",
       "195            90.81       600.6           0.10970            0.15060   \n",
       "141           129.00      1233.0           0.13140            0.22360   \n",
       "319            81.76       515.9           0.08409            0.04712   \n",
       "..               ...         ...               ...                ...   \n",
       "420            86.43       520.5           0.12490            0.19370   \n",
       "279            98.37       670.0           0.11850            0.17240   \n",
       "390            73.23       394.5           0.13430            0.16500   \n",
       "91            107.50       830.9           0.12570            0.19970   \n",
       "297            85.10       553.6           0.11370            0.07974   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "107          0.19370               0.08442          0.2983   \n",
       "437          0.11170               0.07453          0.2725   \n",
       "195          0.17640               0.08235          0.3024   \n",
       "141          0.28020               0.12160          0.2792   \n",
       "319          0.02237               0.02832          0.1901   \n",
       "..               ...                   ...             ...   \n",
       "420          0.25600               0.06664          0.3035   \n",
       "279          0.14560               0.09993          0.2955   \n",
       "390          0.08615               0.06696          0.2937   \n",
       "91           0.28460               0.14760          0.2556   \n",
       "297          0.06120               0.07160          0.1978   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "107                  0.07185  \n",
       "437                  0.07234  \n",
       "195                  0.06949  \n",
       "141                  0.08158  \n",
       "319                  0.05932  \n",
       "..                       ...  \n",
       "420                  0.08284  \n",
       "279                  0.06912  \n",
       "390                  0.07722  \n",
       "91                   0.06828  \n",
       "297                  0.06915  \n",
       "\n",
       "[171 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5b25f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1=Xtest.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81d01379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail2\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['B'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict([x_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0454ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mail2\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.92894626, 0.07105374]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict_proba([x_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db3f6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.predict_log_proba([x_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0e73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
